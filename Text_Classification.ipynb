{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Classification.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jFjobd52V6iN",
        "colab_type": "text"
      },
      "source": [
        "I will apply the Text Classification techniques to identify the author of the fictions. This dataset contains text from works of fiction written by spooky authors of the public domain: Edgar Allan Poe, HP Lovecraft and Mary Shelley. Your objective is to accurately identify the author of the sentences in the test set.\n",
        "\n",
        "The data was prepared by chunking larger texts into sentences using CoreNLP's MaxEnt sentence tokenizer, so you may notice the odd non-sentence here and there. The problem requires here to predict the author, i.e. EAP, HPL and MWS given the text. In simpler words, text classification with 3 different classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QmqQ-wA0WBYN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import xgboost as xgb\n",
        "from sklearn.svm import SVC\n",
        "from sklearn import preprocessing, decomposition, model_selection, metrics, pipeline\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
        "from sklearn.decomposition import TruncatedSVD\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from nltk import word_tokenize\n",
        "from nltk.corpus import stopwords"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "44kfDO5yWSW7",
        "colab_type": "text"
      },
      "source": [
        "Load data;\n",
        "\n",
        "I'll first load the data and split the data into train and test. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qG4aNQNFWVSd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "fdcd29c2-bd1e-4ff5-9b62-7f53691a27ab"
      },
      "source": [
        "data = pd.read_csv('https://raw.githubusercontent.com/zariable/UW-MSIS541/master/assignments/hw1/data/data.csv')\n",
        "data"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>text</th>\n",
              "      <th>author</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>id26305</td>\n",
              "      <td>This process, however, afforded me no means of...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>id17569</td>\n",
              "      <td>It never once occurred to me that the fumbling...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>id11008</td>\n",
              "      <td>In his left hand was a gold snuff box, from wh...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>id27763</td>\n",
              "      <td>How lovely is spring As we looked from Windsor...</td>\n",
              "      <td>MWS</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>id12958</td>\n",
              "      <td>Finding nothing else, not even gold, the Super...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19574</th>\n",
              "      <td>id17718</td>\n",
              "      <td>I could have fancied, while I looked at it, th...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19575</th>\n",
              "      <td>id08973</td>\n",
              "      <td>The lids clenched themselves together as if in...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19576</th>\n",
              "      <td>id05267</td>\n",
              "      <td>Mais il faut agir that is to say, a Frenchman ...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19577</th>\n",
              "      <td>id17513</td>\n",
              "      <td>For an item of news like this, it strikes us i...</td>\n",
              "      <td>EAP</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19578</th>\n",
              "      <td>id00393</td>\n",
              "      <td>He laid a gnarled claw on my shoulder, and it ...</td>\n",
              "      <td>HPL</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>19579 rows Ã— 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "            id                                               text author\n",
              "0      id26305  This process, however, afforded me no means of...    EAP\n",
              "1      id17569  It never once occurred to me that the fumbling...    HPL\n",
              "2      id11008  In his left hand was a gold snuff box, from wh...    EAP\n",
              "3      id27763  How lovely is spring As we looked from Windsor...    MWS\n",
              "4      id12958  Finding nothing else, not even gold, the Super...    HPL\n",
              "...        ...                                                ...    ...\n",
              "19574  id17718  I could have fancied, while I looked at it, th...    EAP\n",
              "19575  id08973  The lids clenched themselves together as if in...    EAP\n",
              "19576  id05267  Mais il faut agir that is to say, a Frenchman ...    EAP\n",
              "19577  id17513  For an item of news like this, it strikes us i...    EAP\n",
              "19578  id00393  He laid a gnarled claw on my shoulder, and it ...    HPL\n",
              "\n",
              "[19579 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dREZyR0HWdT4",
        "colab_type": "text"
      },
      "source": [
        "I'll first preprocess the label by converting the label from string into integer. In particular, I will use the LabelEncoder from scikit-learn to convert text labels to integers, 0, 1 2."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1V53rw_jWimS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "826a1828-8fe0-4272-d691-f5d1457d179d"
      },
      "source": [
        "# label encode the author names into 0, 1 and 2 for easy evaluation.\n",
        "y = preprocessing.LabelEncoder().fit_transform(data.author.values)\n",
        "y"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 1, 0, ..., 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rw_DT4q_W1Rl",
        "colab_type": "text"
      },
      "source": [
        "Then, I will randomly split the original data into train and test where training data is used to train the text classifier and test data is used to evaluate the model performance. We can do it using train_test_split from the model_selection module of scikit-learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zRp7SbgeW7DS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "dfd58da0-3fc8-41e9-cf34-63cf3938c577"
      },
      "source": [
        "# split the data into train and test\n",
        "x_train, x_test, y_train, y_test = train_test_split(\n",
        "    data.text.values, y, \n",
        "    stratify=y, \n",
        "    random_state=42, \n",
        "    test_size=0.1, \n",
        "    shuffle=True\n",
        ")\n",
        "\n",
        "print(x_train.shape)\n",
        "print(x_test.shape)\n",
        "\n",
        "# print the first training example\n",
        "print(x_train[0])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(17621,)\n",
            "(1958,)\n",
            "Her hair was the brightest living gold, and despite the poverty of her clothing, seemed to set a crown of distinction on her head.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xwirGYz6XBJ6",
        "colab_type": "text"
      },
      "source": [
        "Task 1; Build a Naive Bayes Model\n",
        "\n",
        "The very first model is a TF-IDF (Term Frequency - Inverse Document Frequency) followed by a Naive Bayes classifier.\n",
        "\n",
        "I will also use Grid Search to find the best hyper parameter from the following settings;\n",
        "\n",
        "- Differnet ngram range\n",
        "- Weather or not to remove the stop words\n",
        "- Weather or not to apply IDF\n",
        "\n",
        "After identifying the best model, I will use that model to make predictions on the test data and report its accuracy.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k4hPGlfEXfrz",
        "colab_type": "text"
      },
      "source": [
        "Here, I converted the raw text into a vector of counts before feeding into a ML model. In sklearn, we have a API called CountVectorizer to the job for us."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zUGHBcHyXYM4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "964240aa-0bcf-4136-ac24-2f14bbfb7354"
      },
      "source": [
        "# Extracting features from text files\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "\n",
        "count_vect = CountVectorizer(\n",
        "    stop_words = 'english',\n",
        "    max_features = None,\n",
        "    ngram_range = (1, 1)\n",
        ")\n",
        "\n",
        "X_train_counts = count_vect.fit_transform(x_train)\n",
        "X_train_counts.shape"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17621, 23675)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UGqXMAfKXp_D",
        "colab_type": "text"
      },
      "source": [
        "TF-IDF; features from text Similar to raw count vector. Sklearn has a API called TfidfTransformer which convert raw counts ot TF-IDF feature representation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yABYj5xlXnxl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "b8350ff6-ed3d-481e-f0b1-5d3d1d3f6015"
      },
      "source": [
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "\n",
        "tfidf_transformer = TfidfTransformer(\n",
        "    norm = 'l2',\n",
        "    use_idf = True,\n",
        "    smooth_idf = True\n",
        ")\n",
        "\n",
        "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
        "X_train_tfidf.shape\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17621, 23675)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Wt70k0KXwb9",
        "colab_type": "text"
      },
      "source": [
        "Train Naive Bayes Model\n",
        "\n",
        "Given the TFIDF features for the data, we are ready to train the Naive Bayes classifier.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4GpyA4YZXuAq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Naive Bayes (NB) classifier on training data.\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "\n",
        "clf = MultinomialNB().fit(X_train_tfidf, y_train)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JN7D0GcX17U",
        "colab_type": "text"
      },
      "source": [
        "Buliding the  pipeline to connect all the components together. It's another way to connect both the feature generation and model training steps into one is to use the pipeline API."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-YoS3fDXzuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Building a pipeline: We can write less code and do all of the above,as follows:\n",
        "# The names â€˜vectâ€™ , â€˜tfidfâ€™ and â€˜clfâ€™ are arbitrary but will be used later.\n",
        "# I will be using the 'text_clf' going forward.\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "text_clf = Pipeline(\n",
        "    [\n",
        "        ('vect', CountVectorizer()), \n",
        "        ('tfidf', TfidfTransformer()), \n",
        "        ('clf', MultinomialNB())\n",
        "    ]\n",
        ")\n",
        "\n",
        "text_clf = text_clf.fit(x_train, y_train)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8-s0Fs4lYBt8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "6018fa2f-f91c-4b61-8afb-1a51f3ec0ff9"
      },
      "source": [
        "# Performance of NB Classifier\n",
        "import numpy as np\n",
        "predicted = text_clf.predict(x_test)\n",
        "np.mean(predicted == y_test)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8161389172625128"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sandzeoLYHtj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "639fc7a1-4146-4b16-bf79-012c1e3048e7"
      },
      "source": [
        "#Grid Search\n",
        "# Here, I am creating a list of parameters for which I would like to do performance tuning. \n",
        "# All the parameters name start with the classifier name. \n",
        "# E.g. vect__ngram_range; here I am  telling to use unigram, bigrams and trigrams and choose the one which is optimal.\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters = {'vect__ngram_range': [(1, 2), (2, 3)],'vect__stop_words' : ('english', None), 'tfidf__use_idf': (True, False)}\n",
        "parameters"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tfidf__use_idf': (True, False),\n",
              " 'vect__ngram_range': [(1, 2), (2, 3)],\n",
              " 'vect__stop_words': ('english', None)}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfcWni_7YNLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Next,i'll create an instance of the grid search by passing the classifier, parameters \n",
        "# and n_jobs=-1 which tells to use multiple cores from user machine.\n",
        "gs_clf = GridSearchCV(text_clf, parameters, n_jobs=1, cv=2)\n",
        "gs_clf = gs_clf.fit(x_train, y_train)"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xny4qqddYRQb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "14da9c5f-775c-47c7-caa3-7309d3a91849"
      },
      "source": [
        "# To see the best mean score and the params, run the following code\n",
        "\n",
        "gs_clf.best_score_\n",
        "gs_clf.best_params_\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tfidf__use_idf': True,\n",
              " 'vect__ngram_range': (1, 2),\n",
              " 'vect__stop_words': 'english'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUgvZqbAYTkc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "182a0e14-524a-48d2-ec80-21b3ca5670d5"
      },
      "source": [
        "predicted = gs_clf.predict(x_test)\n",
        "np.mean(predicted == y_test)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7819203268641471"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iTvegPWJYaJy",
        "colab_type": "text"
      },
      "source": [
        "Here, the Naive approach gives an accuracy of 78%."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VW56O3ZtZyxD",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eF7nT1rnZKJX",
        "colab_type": "text"
      },
      "source": [
        "Task 2: Build a Support Vector Machines (SVM) Model\n",
        "Similar to the first task, now I'll built a SVM model for the same task. I will also use Grid Search to find the best hyper parameters and report the accuracy on the test from the best model."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mmuZfMnCYXc1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "7b15fdcb-b29e-49d1-d78c-f46f9e9be33a"
      },
      "source": [
        "\n",
        "# Training Support Vector Machines - SVM and calculating its performance\n",
        "\n",
        "from sklearn.svm import LinearSVC\n",
        "\n",
        "text_clf_svm = Pipeline(\n",
        "    [\n",
        "        ('vect', CountVectorizer()), \n",
        "        ('tfidf', TfidfTransformer()),\n",
        "        ('clf-svm', LinearSVC(random_state=0))\n",
        "    ]\n",
        ")\n",
        "\n",
        "text_clf_svm = text_clf_svm.fit(x_train, y_train)\n",
        "predicted_svm = text_clf_svm.predict(x_test)\n",
        "np.mean(predicted_svm == y_test)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8381001021450459"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAXeJXT-ZUXs",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "a6b421cc-2e46-4ab1-e881-04543f9f4027"
      },
      "source": [
        "# Similarly doing grid search for SVM\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters_svm = {'vect__ngram_range': [(1, 2), (2,3)], 'vect__stop_words' : ('english', None), 'tfidf__use_idf': (True, False)}\n",
        "\n",
        "gs_clf_svm = GridSearchCV(text_clf_svm, parameters_svm, n_jobs=1, cv=2)\n",
        "gs_clf_svm = gs_clf_svm.fit(x_train, y_train)\n",
        "\n",
        "gs_clf_svm.best_score_\n",
        "gs_clf_svm.best_params_"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'tfidf__use_idf': True, 'vect__ngram_range': (1, 2), 'vect__stop_words': None}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNpYDcWyZYiL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "0b77d2b5-f914-49bb-dddc-bd465ff062fb"
      },
      "source": [
        "predicted = gs_clf_svm.predict(x_test)\n",
        "np.mean(predicted == y_test)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8452502553626149"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J_kdUP0YZdvK",
        "colab_type": "text"
      },
      "source": [
        "In case of SVM, the accuracy is 84% which is better than NB classifier by not using stopwords but using idf."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wX8DMl-9Zatj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}